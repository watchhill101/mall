import React, { useState, useRef, useEffect, useCallback, useMemo } from 'react';
import { Button, Input, Card, Avatar, Typography, Space, Spin, message, Tooltip, Badge } from 'antd';
import { 
  SendOutlined, 
  ClearOutlined, 
  SoundOutlined,
  AudioOutlined,
  CloseOutlined,
  RobotOutlined,
  UserOutlined,
  ExpandOutlined,
  CompressOutlined
} from '@ant-design/icons';
import { askGemini } from '../../utils/geminiApi';
import './AiAssistant.scss';

const { TextArea } = Input;
const { Text, Paragraph } = Typography;

const AiAssistant = () => {
  const [isOpen, setIsOpen] = useState(false);
  const [isExpanded, setIsExpanded] = useState(false);
  const [conversation, setConversation] = useState([
    {
      id: 1,
      type: 'ai',
      content: '‰Ω†Â•ΩÔºÅÊàëÊòØ‰Ω†ÁöÑAIÂä©ÊâãÂ∞èÈõ™ÔºåÊúâ‰ªÄ‰πàÂèØ‰ª•Â∏ÆÂä©‰Ω†ÁöÑÂêóÔºüüòä',
      timestamp: new Date(),
    }
  ]);
  const [inputText, setInputText] = useState('');
  const [isLoading, setIsLoading] = useState(false);
  const [isSpeaking, setIsSpeaking] = useState(false);
  const [isListening, setIsListening] = useState(false);
  
  const messagesEndRef = useRef(null);
  const recognitionRef = useRef(null);
  const synthRef = useRef(null);

  // ÊªöÂä®Âà∞ÊúÄÊñ∞Ê∂àÊÅØ
  const scrollToBottom = () => {
    messagesEndRef.current?.scrollIntoView({ behavior: 'smooth' });
  };

  useEffect(() => {
    scrollToBottom();
  }, [conversation]);

  // ÂàùÂßãÂåñËØ≠Èü≥ËØÜÂà´
  useEffect(() => {
    if ('webkitSpeechRecognition' in window || 'SpeechRecognition' in window) {
      const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
      recognitionRef.current = new SpeechRecognition();
      recognitionRef.current.continuous = false;
      recognitionRef.current.interimResults = false;
      recognitionRef.current.lang = 'zh-CN';
      
      recognitionRef.current.onresult = (event) => {
        const transcript = event.results[0][0].transcript;
        setInputText(transcript);
        setIsListening(false);
      };
      
      recognitionRef.current.onend = () => {
        setIsListening(false);
      };
      
      recognitionRef.current.onerror = (event) => {
        console.error('ËØ≠Èü≥ËØÜÂà´ÈîôËØØ:', event.error);
        setIsListening(false);
        message.error('ËØ≠Èü≥ËØÜÂà´Â§±Ë¥•ÔºåËØ∑ÈáçËØï');
      };
    }

    // ÂàùÂßãÂåñËØ≠Èü≥ÂêàÊàê
    if ('speechSynthesis' in window) {
      synthRef.current = window.speechSynthesis;
    }

    return () => {
      if (recognitionRef.current) {
        recognitionRef.current.stop();
      }
      if (synthRef.current) {
        synthRef.current.cancel();
      }
    };
  }, []);

  // ÂèëÈÄÅÊ∂àÊÅØÁªôAI
  const sendMessage = useCallback(async () => {
    if (!inputText.trim()) return;

    const userMessage = {
      id: Date.now(),
      type: 'user',
      content: inputText.trim(),
      timestamp: new Date(),
    };

    setConversation(prev => [...prev, userMessage]);
    const currentInputText = inputText.trim();
    setInputText('');
    setIsLoading(true);

    try {
      const aiResponse = await askGemini(currentInputText);
      
      const aiMessage = {
        id: Date.now() + 1,
        type: 'ai',
        content: aiResponse,
        timestamp: new Date(),
      };
      
      setConversation(prev => [...prev, aiMessage]);
      
      // Êí≠ÊîæAIÂõûÂ§çÁöÑËØ≠Èü≥
      if (synthRef.current) {
        synthRef.current.cancel();
        
        const utterance = new SpeechSynthesisUtterance(aiResponse);
        utterance.lang = 'zh-CN';
        utterance.rate = 0.9;
        utterance.pitch = 1.1;
        utterance.volume = 0.8;
        
        utterance.onstart = () => setIsSpeaking(true);
        utterance.onend = () => setIsSpeaking(false);
        utterance.onerror = () => setIsSpeaking(false);
        
        synthRef.current.speak(utterance);
      }
      
    } catch (error) {
      console.error('AIÂìçÂ∫îÈîôËØØ:', error);
      const errorMessage = {
        id: Date.now() + 1,
        type: 'ai',
        content: 'Êä±Ê≠âÔºåÊàëÁé∞Âú®Êó†Ê≥ïÂõûÂ§çÔºåËØ∑Á®çÂêéÂÜçËØï„ÄÇüòî',
        timestamp: new Date(),
      };
      setConversation(prev => [...prev, errorMessage]);
      message.error('AIÂä©ÊâãÊöÇÊó∂Êó†Ê≥ïÂìçÂ∫î');
    } finally {
      setIsLoading(false);
    }
  }, [inputText]);

  // ÊñáÂ≠óËΩ¨ËØ≠Èü≥
  const speakText = useCallback((text) => {
    if (!synthRef.current) return;
    
    // ÂÅúÊ≠¢ÂΩìÂâçÊí≠Êîæ
    synthRef.current.cancel();
    
    const utterance = new SpeechSynthesisUtterance(text);
    utterance.lang = 'zh-CN';
    utterance.rate = 0.9;
    utterance.pitch = 1.1;
    utterance.volume = 0.8;
    
    utterance.onstart = () => setIsSpeaking(true);
    utterance.onend = () => setIsSpeaking(false);
    utterance.onerror = () => setIsSpeaking(false);
    
    synthRef.current.speak(utterance);
  }, []);

  // ÂºÄÂßãËØ≠Èü≥ËØÜÂà´
  const startListening = useCallback(() => {
    if (!recognitionRef.current) {
      message.warning('ÊÇ®ÁöÑÊµèËßàÂô®‰∏çÊîØÊåÅËØ≠Èü≥ËØÜÂà´ÂäüËÉΩ');
      return;
    }
    
    try {
      setIsListening(true);
      recognitionRef.current.start();
    } catch (error) {
      console.error('ËØ≠Èü≥ËØÜÂà´ÂêØÂä®Â§±Ë¥•:', error);
      setIsListening(false);
      message.error('ËØ≠Èü≥ËØÜÂà´ÂêØÂä®Â§±Ë¥•');
    }
  }, []);

  // Ê∏ÖÁ©∫ÂØπËØù
  const clearConversation = useCallback(() => {
    setConversation([
      {
        id: 1,
        type: 'ai',
        content: 'ÂØπËØùÂ∑≤Ê∏ÖÁ©∫ÔºåÊúâ‰ªÄ‰πàÊñ∞ÈóÆÈ¢òÊÉ≥ÈóÆÊàëÂêóÔºüüòä',
        timestamp: new Date(),
      }
    ]);
  }, []);

  // Â§ÑÁêÜÂõûËΩ¶ÈîÆÂèëÈÄÅ
  const handleKeyPress = useCallback((e) => {
    if (e.key === 'Enter' && !e.shiftKey) {
      e.preventDefault();
      sendMessage();
    }
  }, [sendMessage]);

  // Ê†ºÂºèÂåñÊó∂Èó¥
  const formatTime = useCallback((date) => {
    return date.toLocaleTimeString('zh-CN', { 
      hour: '2-digit', 
      minute: '2-digit' 
    });
  }, []);

  // Â§ÑÁêÜËæìÂÖ•ÂèòÂåñ
  const handleInputChange = useCallback((e) => {
    setInputText(e.target.value);
  }, []);

  // ‰∏ªÊåâÈíÆÁªÑ‰ª∂Ôºà‰ΩøÁî® useMemo ÈÅøÂÖçÈáçÂ§çÊ∏≤ÊüìÔºâ
  const mainButtonElement = useMemo(() => (
    <div className="ai-assistant-trigger">
      <Badge dot={!isOpen && conversation.length > 1}>
        <Button
          type="primary"
          shape="circle"
          size="large"
          icon={<RobotOutlined />}
          onClick={() => setIsOpen(!isOpen)}
          className="main-trigger-btn"
          title="AIÂä©ÊâãÂ∞èÈõ™"
        />
      </Badge>
    </div>
  ), [isOpen, conversation.length]);

  // ÂØπËØùÁïåÈù¢
  const ChatInterface = () => (
    <Card
      className={`ai-chat-card ${isExpanded ? 'expanded' : ''}`}
      title={
        <div className="chat-header">
          <Space>
            <Avatar 
              size="small" 
              style={{ backgroundColor: '#87d068' }}
              icon={<RobotOutlined />}
            />
            <Text strong>AIÂä©ÊâãÂ∞èÈõ™</Text>
            <Badge status="success" text="Âú®Á∫ø" />
          </Space>
          <Space>
            <Tooltip title={isExpanded ? "Êî∂Ëµ∑" : "Â±ïÂºÄ"}>
              <Button
                type="text"
                size="small"
                icon={isExpanded ? <CompressOutlined /> : <ExpandOutlined />}
                onClick={() => setIsExpanded(!isExpanded)}
              />
            </Tooltip>
            <Tooltip title="Ê∏ÖÁ©∫ÂØπËØù">
              <Button
                type="text"
                size="small"
                icon={<ClearOutlined />}
                onClick={clearConversation}
              />
            </Tooltip>
            <Tooltip title="ÂÖ≥Èó≠">
              <Button
                type="text"
                size="small"
                icon={<CloseOutlined />}
                onClick={() => setIsOpen(false)}
              />
            </Tooltip>
          </Space>
        </div>
      }
      bodyStyle={{ 
        padding: 0, 
        height: isExpanded ? '600px' : '400px',
        display: 'flex',
        flexDirection: 'column'
      }}
    >
      {/* ÂØπËØùÂå∫Âüü */}
      <div className="chat-messages">
        {conversation.map((msg) => (
          <div 
            key={msg.id} 
            className={`message ${msg.type === 'user' ? 'user-message' : 'ai-message'}`}
          >
            <div className="message-avatar">
              {msg.type === 'user' ? (
                <Avatar size="small" icon={<UserOutlined />} />
              ) : (
                <Avatar 
                  size="small" 
                  style={{ backgroundColor: '#87d068' }}
                  icon={<RobotOutlined />}
                />
              )}
            </div>
            <div className="message-content">
              <div className="message-bubble">
                <Paragraph className="message-text">
                  {msg.content}
                </Paragraph>
              </div>
              <div className="message-time">
                {formatTime(msg.timestamp)}
                {msg.type === 'ai' && (
                  <Button
                    type="text"
                    size="small"
                    icon={<SoundOutlined />}
                    loading={isSpeaking}
                    onClick={() => speakText(msg.content)}
                    className="speak-btn"
                    title="Êí≠ÊîæËØ≠Èü≥"
                  />
                )}
              </div>
            </div>
          </div>
        ))}
        
        {isLoading && (
          <div className="message ai-message">
            <div className="message-avatar">
              <Avatar 
                size="small" 
                style={{ backgroundColor: '#87d068' }}
                icon={<RobotOutlined />}
              />
            </div>
            <div className="message-content">
              <div className="message-bubble">
                <Spin size="small" />
                <Text type="secondary" style={{ marginLeft: '8px' }}>
                  Â∞èÈõ™Ê≠£Âú®ÊÄùËÄÉ...
                </Text>
              </div>
            </div>
          </div>
        )}
        
        <div ref={messagesEndRef} />
      </div>

      {/* ËæìÂÖ•Âå∫Âüü */}
      <div className="chat-input">
        <TextArea
          value={inputText}
          onChange={handleInputChange}
          onKeyPress={handleKeyPress}
          placeholder="ËæìÂÖ•Ê∂àÊÅØ...ÔºàÊåâEnterÂèëÈÄÅÔºåShift+EnterÊç¢Ë°åÔºâ"
          autoSize={{ minRows: 1, maxRows: 3 }}
          disabled={isLoading}
        />
        <div className="input-actions">
          <Space>
            <Tooltip title="ËØ≠Èü≥ËæìÂÖ•">
              <Button
                type="text"
                icon={<AudioOutlined />}
                loading={isListening}
                onClick={startListening}
                disabled={isLoading}
              />
            </Tooltip>
            <Button
              type="primary"
              icon={<SendOutlined />}
              onClick={sendMessage}
              loading={isLoading}
              disabled={!inputText.trim()}
            >
              ÂèëÈÄÅ
            </Button>
          </Space>
        </div>
      </div>
    </Card>
  );

  return (
    <div className="ai-assistant-container">
      {mainButtonElement}
      {isOpen && <ChatInterface />}
    </div>
  );
};

export default AiAssistant;
