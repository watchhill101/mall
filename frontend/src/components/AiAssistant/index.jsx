import React, { useState, useRef, useEffect, useCallback, useMemo } from 'react';
import { Button, Input, Card, Avatar, Typography, Space, Spin, message, Tooltip, Badge } from 'antd';
import { 
  SendOutlined, 
  ClearOutlined, 
  SoundOutlined,
  AudioOutlined,
  CloseOutlined,
  RobotOutlined,
  UserOutlined,
  ExpandOutlined,
  CompressOutlined
} from '@ant-design/icons';
import { askGemini } from '../../utils/geminiApi';
import './AiAssistant.scss';

const { TextArea } = Input;
const { Text, Paragraph } = Typography;

const AiAssistant = () => {
  const [isOpen, setIsOpen] = useState(false);
  const [isExpanded, setIsExpanded] = useState(false);
  const [conversation, setConversation] = useState([
    {
      id: 1,
      type: 'ai',
      content: 'ä½ å¥½ï¼æˆ‘æ˜¯ä½ çš„AIåŠ©æ‰‹å°é›ªï¼Œæœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©ä½ çš„å—ï¼ŸğŸ˜Š',
      timestamp: new Date(),
    }
  ]);
  const [inputText, setInputText] = useState('');
  const [isLoading, setIsLoading] = useState(false);
  const [isSpeaking, setIsSpeaking] = useState(false);
  const [isListening, setIsListening] = useState(false);
  
  const messagesEndRef = useRef(null);
  const recognitionRef = useRef(null);
  const synthRef = useRef(null);

  // æ»šåŠ¨åˆ°æœ€æ–°æ¶ˆæ¯
  const scrollToBottom = () => {
    messagesEndRef.current?.scrollIntoView({ behavior: 'smooth' });
  };

  useEffect(() => {
    scrollToBottom();
  }, [conversation]);

  // åˆå§‹åŒ–è¯­éŸ³è¯†åˆ«
  useEffect(() => {
    if ('webkitSpeechRecognition' in window || 'SpeechRecognition' in window) {
      const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
      recognitionRef.current = new SpeechRecognition();
      recognitionRef.current.continuous = false;
      recognitionRef.current.interimResults = false;
      recognitionRef.current.lang = 'zh-CN';
      
      recognitionRef.current.onresult = (event) => {
        const transcript = event.results[0][0].transcript;
        setInputText(transcript);
        setIsListening(false);
      };
      
      recognitionRef.current.onend = () => {
        setIsListening(false);
      };
      
      recognitionRef.current.onerror = (event) => {
        console.error('è¯­éŸ³è¯†åˆ«é”™è¯¯:', event.error);
        setIsListening(false);
        message.error('è¯­éŸ³è¯†åˆ«å¤±è´¥ï¼Œè¯·é‡è¯•');
      };
    }

    // åˆå§‹åŒ–è¯­éŸ³åˆæˆ
    if ('speechSynthesis' in window) {
      synthRef.current = window.speechSynthesis;
    }

    return () => {
      if (recognitionRef.current) {
        recognitionRef.current.stop();
      }
      if (synthRef.current) {
        synthRef.current.cancel();
      }
    };
  }, []);

  // å‘é€æ¶ˆæ¯ç»™AI
  const sendMessage = useCallback(async () => {
    if (!inputText.trim()) return;

    const userMessage = {
      id: Date.now(),
      type: 'user',
      content: inputText.trim(),
      timestamp: new Date(),
    };

    setConversation(prev => [...prev, userMessage]);
    const currentInputText = inputText.trim();
    setInputText('');
    setIsLoading(true);

    try {
      const aiResponse = await askGemini(currentInputText);
      
      const aiMessage = {
        id: Date.now() + 1,
        type: 'ai',
        content: aiResponse,
        timestamp: new Date(),
      };
      
      setConversation(prev => [...prev, aiMessage]);
      
      // æ’­æ”¾AIå›å¤çš„è¯­éŸ³
      if (synthRef.current) {
        synthRef.current.cancel();
        
        const utterance = new SpeechSynthesisUtterance(aiResponse);
        utterance.lang = 'zh-CN';
        utterance.rate = 0.9;
        utterance.pitch = 1.1;
        utterance.volume = 0.8;
        
        utterance.onstart = () => setIsSpeaking(true);
        utterance.onend = () => setIsSpeaking(false);
        utterance.onerror = () => setIsSpeaking(false);
        
        synthRef.current.speak(utterance);
      }
      
    } catch (error) {
      console.error('AIå“åº”é”™è¯¯:', error);
      const errorMessage = {
        id: Date.now() + 1,
        type: 'ai',
        content: 'æŠ±æ­‰ï¼Œæˆ‘ç°åœ¨æ— æ³•å›å¤ï¼Œè¯·ç¨åå†è¯•ã€‚ğŸ˜”',
        timestamp: new Date(),
      };
      setConversation(prev => [...prev, errorMessage]);
      message.error('AIåŠ©æ‰‹æš‚æ—¶æ— æ³•å“åº”');
    } finally {
      setIsLoading(false);
    }
  }, [inputText]);

  // æ–‡å­—è½¬è¯­éŸ³
  const speakText = useCallback((text) => {
    if (!synthRef.current) return;
    
    // åœæ­¢å½“å‰æ’­æ”¾
    synthRef.current.cancel();
    
    const utterance = new SpeechSynthesisUtterance(text);
    utterance.lang = 'zh-CN';
    utterance.rate = 0.9;
    utterance.pitch = 1.1;
    utterance.volume = 0.8;
    
    utterance.onstart = () => setIsSpeaking(true);
    utterance.onend = () => setIsSpeaking(false);
    utterance.onerror = () => setIsSpeaking(false);
    
    synthRef.current.speak(utterance);
  }, []);

  // å¼€å§‹è¯­éŸ³è¯†åˆ«
  const startListening = useCallback(() => {
    if (!recognitionRef.current) {
      message.warning('æ‚¨çš„æµè§ˆå™¨ä¸æ”¯æŒè¯­éŸ³è¯†åˆ«åŠŸèƒ½');
      return;
    }
    
    try {
      setIsListening(true);
      recognitionRef.current.start();
    } catch (error) {
      console.error('è¯­éŸ³è¯†åˆ«å¯åŠ¨å¤±è´¥:', error);
      setIsListening(false);
      message.error('è¯­éŸ³è¯†åˆ«å¯åŠ¨å¤±è´¥');
    }
  }, []);

  // æ¸…ç©ºå¯¹è¯
  const clearConversation = useCallback(() => {
    setConversation([
      {
        id: 1,
        type: 'ai',
        content: 'å¯¹è¯å·²æ¸…ç©ºï¼Œæœ‰ä»€ä¹ˆæ–°é—®é¢˜æƒ³é—®æˆ‘å—ï¼ŸğŸ˜Š',
        timestamp: new Date(),
      }
    ]);
  }, []);

  // å¤„ç†å›è½¦é”®å‘é€
  const handleKeyPress = useCallback((e) => {
    if (e.key === 'Enter' && !e.shiftKey) {
      e.preventDefault();
      sendMessage();
    }
  }, [sendMessage]);

  // æ ¼å¼åŒ–æ—¶é—´
  const formatTime = useCallback((date) => {
    return date.toLocaleTimeString('zh-CN', { 
      hour: '2-digit', 
      minute: '2-digit' 
    });
  }, []);

  // å¤„ç†è¾“å…¥å˜åŒ–
  const handleInputChange = useCallback((e) => {
    setInputText(e.target.value);
  }, []);

  // ä¸»æŒ‰é’®ç»„ä»¶ï¼ˆä½¿ç”¨ useMemo é¿å…é‡å¤æ¸²æŸ“ï¼‰
  const mainButtonElement = useMemo(() => (
    <div className="ai-assistant-trigger">
      <Badge dot={!isOpen && conversation.length > 1}>
        <Button
          type="primary"
          shape="circle"
          size="large"
          icon={<RobotOutlined />}
          onClick={() => setIsOpen(!isOpen)}
          className="main-trigger-btn"
          title="AIåŠ©æ‰‹å°é›ª"
        />
      </Badge>
    </div>
  ), [isOpen, conversation.length]);

  // å¯¹è¯ç•Œé¢
  const ChatInterface = () => (
    <Card
      className={`ai-chat-card ${isExpanded ? 'expanded' : ''}`}
      title={
        <div className="chat-header">
          <Space>
            <Avatar 
              size="small" 
              style={{ backgroundColor: '#87d068' }}
              icon={<RobotOutlined />}
            />
            <Text strong>AIåŠ©æ‰‹å°é›ª</Text>
            <Badge status="success" text="åœ¨çº¿" />
          </Space>
          <Space>
            <Tooltip title={isExpanded ? "æ”¶èµ·" : "å±•å¼€"}>
              <Button
                type="text"
                size="small"
                icon={isExpanded ? <CompressOutlined /> : <ExpandOutlined />}
                onClick={() => setIsExpanded(!isExpanded)}
              />
            </Tooltip>
            <Tooltip title="æ¸…ç©ºå¯¹è¯">
              <Button
                type="text"
                size="small"
                icon={<ClearOutlined />}
                onClick={clearConversation}
              />
            </Tooltip>
            <Tooltip title="å…³é—­">
              <Button
                type="text"
                size="small"
                icon={<CloseOutlined />}
                onClick={() => setIsOpen(false)}
              />
            </Tooltip>
          </Space>
        </div>
      }
      bodyStyle={{ 
        padding: 0, 
        height: isExpanded ? '600px' : '400px',
        display: 'flex',
        flexDirection: 'column'
      }}
    >
      {/* å¯¹è¯åŒºåŸŸ */}
      <div className="chat-messages">
        {conversation.map((msg) => (
          <div 
            key={msg.id} 
            className={`message ${msg.type === 'user' ? 'user-message' : 'ai-message'}`}
          >
            <div className="message-avatar">
              {msg.type === 'user' ? (
                <Avatar size="small" icon={<UserOutlined />} />
              ) : (
                <Avatar 
                  size="small" 
                  style={{ backgroundColor: '#87d068' }}
                  icon={<RobotOutlined />}
                />
              )}
            </div>
            <div className="message-content">
              <div className="message-bubble">
                <Paragraph className="message-text">
                  {msg.content}
                </Paragraph>
              </div>
              <div className="message-time">
                {formatTime(msg.timestamp)}
                {msg.type === 'ai' && (
                  <Button
                    type="text"
                    size="small"
                    icon={<SoundOutlined />}
                    loading={isSpeaking}
                    onClick={() => speakText(msg.content)}
                    className="speak-btn"
                    title="æ’­æ”¾è¯­éŸ³"
                  />
                )}
              </div>
            </div>
          </div>
        ))}
        
        {isLoading && (
          <div className="message ai-message">
            <div className="message-avatar">
              <Avatar 
                size="small" 
                style={{ backgroundColor: '#87d068' }}
                icon={<RobotOutlined />}
              />
            </div>
            <div className="message-content">
              <div className="message-bubble">
                <Spin size="small" />
                <Text type="secondary" style={{ marginLeft: '8px' }}>
                  å°é›ªæ­£åœ¨æ€è€ƒ...
                </Text>
              </div>
            </div>
          </div>
        )}
        
        <div ref={messagesEndRef} />
      </div>

      {/* è¾“å…¥åŒºåŸŸ */}
      <div className="chat-input">
        <TextArea
          value={inputText}
          onChange={handleInputChange}
          onKeyPress={handleKeyPress}
          placeholder="è¾“å…¥æ¶ˆæ¯...ï¼ˆæŒ‰Enterå‘é€ï¼ŒShift+Enteræ¢è¡Œï¼‰"
          autoSize={{ minRows: 1, maxRows: 3 }}
          disabled={isLoading}
        />
        <div className="input-actions">
          <Space>
            <Tooltip title="è¯­éŸ³è¾“å…¥">
              <Button
                type="text"
                icon={<AudioOutlined />}
                loading={isListening}
                onClick={startListening}
                disabled={isLoading}
              />
            </Tooltip>
            <Button
              type="primary"
              icon={<SendOutlined />}
              onClick={sendMessage}
              loading={isLoading}
              disabled={!inputText.trim()}
            >
              å‘é€
            </Button>
          </Space>
        </div>
      </div>
    </Card>
  );

  return (
    <div className="ai-assistant-container">
      {mainButtonElement}
      {isOpen && <ChatInterface />}
    </div>
  );
};

export default AiAssistant;
